{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3815cb83",
   "metadata": {},
   "source": [
    "### 요구사항 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9614374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    # 텐서 자료형으로 데이터를 다루기 위해 각 Float와 Long 텐서로 변환\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "\n",
    "    # 데이터셋 크기를 반환\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # feature와 target 데이터를 반환\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.X[idx]\n",
    "        target = self.y[idx]\n",
    "        return {'input': feature, 'target': target}\n",
    "\n",
    "    # 데이터 사이즈에 대한 설명 반환\n",
    "    def __str__(self):\n",
    "        str = \"Data Size: {0}, Input Shape: {1}, Target Shape: {2}\".format(\n",
    "            len(self.X), self.X.shape, self.y.shape\n",
    "        )\n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab020b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset):\n",
    "    # X를 FloatTensor로 변환\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 크기 반환\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.X[idx]\n",
    "        return {'input': feature}\n",
    "\n",
    "    def __str__(self):\n",
    "        str = \"Data Size: {0}, Input Shape: {1}\".format(\n",
    "            len(self.X), self.X.shape\n",
    "        )\n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef4e3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset():\n",
    "    # 훈련 데이터와 테스트 데이터의 파일 경로 지정\n",
    "    train_data_path = os.path.join(\"train.csv\")\n",
    "    test_data_path = os.path.join(\"test.csv\")\n",
    "\n",
    "    # DataFrame으로 각 CSV 파일을 읽어옴\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    # 정렬 안 하고 DataFrame을 합침\n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "    # 1 ~ 6까지 전처리 함수 호출\n",
    "    all_df = get_preprocessed_dataset_1(all_df)\n",
    "    all_df = get_preprocessed_dataset_2(all_df)\n",
    "    all_df = get_preprocessed_dataset_3(all_df)\n",
    "    all_df = get_preprocessed_dataset_4(all_df)\n",
    "    all_df = get_preprocessed_dataset_5(all_df)\n",
    "    all_df = get_preprocessed_dataset_6(all_df)\n",
    "\n",
    "    # Survived가 null이 아니라면 훈련 데이터로 사용하고, 기존 인덱스를 초기화하기 위해 reset_index 사용\n",
    "    # 훈련 데이터에서는 Survived이 null이 아닌 행만을 선택하여 사용\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    # 학습해야 할 데이터인 Survived는 따로 추출해놓음\n",
    "    train_y = train_df[\"Survived\"]\n",
    "\n",
    "    # 테스트 데이터에서는 Survived가 null인 행만을 선택하여 사용\n",
    "    # 삭제하는 이유는 테스트에서는 Survived를 제거 -> 정답이 없기에\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "\n",
    "    # TitanicDataset을 이용해 학습용 데이터셋을 생성\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "    # print(dataset)\n",
    "    # 훈련 데이터셋은 80%, 검증 데이터셋은 20%로 분할\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "    # 테스트 데이터는 TitanicTestDataset으로 변환\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "    # print(test_dataset)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e531901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_1(all_df):\n",
    "    # Pclass별 Fare 평균값을 사용하여 Fare 결측치 메우기\n",
    "    Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "    Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]\n",
    "    all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cb7e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_2(all_df):\n",
    "    # name을 세 개의 컬럼으로 분리하여 다시 all_df에 합침\n",
    "    name_df = all_df[\"Name\"].str.split(\"[,.]\", n=2, expand=True)\n",
    "    name_df.columns = [\"family_name\", \"honorific\", \"name\"]\n",
    "    name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "    name_df[\"honorific\"] = name_df[\"honorific\"].str.strip()\n",
    "    name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "    all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8b55c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_3(all_df):\n",
    "    # honorific별 Age 평균값을 사용하여 Age 결측치 메우기\n",
    "    honorific_age_mean = all_df[[\"honorific\", \"Age\"]].groupby(\"honorific\").median().round().reset_index()\n",
    "    honorific_age_mean.columns = [\"honorific\", \"honorific_age_mean\", ]\n",
    "    all_df = pd.merge(all_df, honorific_age_mean, on=\"honorific\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"honorific_age_mean\"]\n",
    "    all_df = all_df.drop([\"honorific_age_mean\"], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aca51a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_4(all_df):\n",
    "    # 가족수(family_num) 컬럼 새롭게 추가\n",
    "    all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "\n",
    "    # 혼자탑승(alone) 컬럼 새롭게 추가\n",
    "    all_df.loc[all_df[\"family_num\"] == 0, \"alone\"] = 1\n",
    "    all_df[\"alone\"].fillna(0, inplace=True)\n",
    "\n",
    "    # 학습에 불필요한 컬럼 제거\n",
    "    all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbce3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_5(all_df):\n",
    "    # honorific 값 개수 줄이기\n",
    "    all_df.loc[\n",
    "        ~(\n",
    "                (all_df[\"honorific\"] == \"Mr\") |\n",
    "                (all_df[\"honorific\"] == \"Miss\") |\n",
    "                (all_df[\"honorific\"] == \"Mrs\") |\n",
    "                (all_df[\"honorific\"] == \"Master\")\n",
    "        ),\n",
    "        \"honorific\"\n",
    "    ] = \"other\"\n",
    "    all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49e2ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_6(all_df):\n",
    "    # 카테고리 변수를 LabelEncoder를 사용하여 수치값으로 변경하기\n",
    "    category_features = all_df.columns[all_df.dtypes == \"object\"]\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for category_feature in category_features:\n",
    "        le = LabelEncoder()\n",
    "        if all_df[category_feature].dtypes == \"object\":\n",
    "            le = le.fit(all_df[category_feature])\n",
    "            all_df[category_feature] = le.transform(all_df[category_feature])\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f903cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # 입력층에서 은닉층으로 넘어갈 땐 n_input에서 30개\n",
    "            nn.Linear(n_input, 30),\n",
    "            # 활성함수는 ReLU 사용\n",
    "            nn.ReLU(),\n",
    "            # 은닉층에서 은닉층은 30개에서 30개\n",
    "            nn.Linear(30, 30),\n",
    "            # 활성함수는 ReLU 사용\n",
    "            nn.ReLU(),\n",
    "            # 은닉층에서 출력층은 30개에서 2개\n",
    "            nn.Linear(30, n_output),\n",
    "        )\n",
    "\n",
    "    # 모델 출력\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16a8e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data_loader):\n",
    "    print(\"[TEST]\")\n",
    "    batch = next(iter(test_data_loader))\n",
    "    print(\"{0}\".format(batch['input'].shape))\n",
    "\n",
    "    # 여기선 입력층은 11개, 출력층은 2개\n",
    "    my_model = MyModel(n_input=11, n_output=2)\n",
    "    # 모델로 예측 수행\n",
    "    output_batch = my_model(batch['input'])\n",
    "    # 예측 데이터 출력\n",
    "    prediction_batch = torch.argmax(output_batch, dim=1)\n",
    "    for idx, prediction in enumerate(prediction_batch, start=892):\n",
    "        print(idx, prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30e456f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 713, validation_dataset.shape: 178, test_dataset: 418\n",
      "################################################## 1\n",
      "0 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "1 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "2 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "3 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 69.3000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "4 - tensor([ 2.0000,  1.0000, 52.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "5 - tensor([ 1.0000,  1.0000, 49.0000,  1.0000,  0.0000, 56.9292,  0.0000, 87.5090,\n",
      "         4.0000,  1.0000,  0.0000]): 1\n",
      "6 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "7 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "8 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "9 - tensor([ 3.0000,  0.0000,  2.0000,  0.0000,  1.0000, 12.2875,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "10 - tensor([ 1.0000,  1.0000, 36.0000,  1.0000,  0.0000, 78.8500,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "11 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "12 - tensor([ 3.0000,  1.0000, 29.0000,  2.0000,  0.0000, 21.6792,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "13 - tensor([ 1.0000,  0.0000, 60.0000,  1.0000,  0.0000, 75.2500,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "14 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 82.1708,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "15 - tensor([ 2.0000,  1.0000, 21.0000,  1.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "16 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "17 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 42.4000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "18 - tensor([ 2.0000,  1.0000, 32.0000,  2.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "19 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "20 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "21 - tensor([  1.0000,   0.0000,  21.0000,   2.0000,   2.0000, 262.3750,   0.0000,\n",
      "         87.5090,   1.0000,   4.0000,   0.0000]): 1\n",
      "22 - tensor([ 3.0000,  1.0000, 34.0000,  1.0000,  1.0000, 14.4000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "23 - tensor([ 1.0000,  1.0000, 61.0000,  0.0000,  0.0000, 33.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "24 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "25 - tensor([  1.0000,   0.0000,  41.0000,   0.0000,   0.0000, 134.5000,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "26 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "27 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "28 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8292,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "29 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "30 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "31 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "32 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "33 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "34 - tensor([  1.0000,   0.0000,  17.0000,   1.0000,   0.0000, 108.9000,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "35 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "36 - tensor([ 2.0000,  1.0000, 16.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "37 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 40.1250,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "38 - tensor([  1.0000,   1.0000,  18.0000,   1.0000,   0.0000, 108.9000,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "39 - tensor([ 1.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.2875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "40 - tensor([ 1.0000,  1.0000, 64.0000,  0.0000,  0.0000, 26.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "41 - tensor([ 3.0000,  1.0000,  0.4200,  0.0000,  1.0000,  8.5167,  0.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "42 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "43 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "44 - tensor([ 2.0000,  0.0000, 33.0000,  0.0000,  2.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "45 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  2.0000, 23.4500,  2.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 0\n",
      "46 - tensor([ 2.0000,  0.0000, 27.0000,  1.0000,  0.0000, 13.8583,  0.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "47 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 26.3875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "48 - tensor([ 3.0000,  0.0000, 19.0000,  1.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "49 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "50 - tensor([ 2.0000,  0.0000, 35.0000,  0.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "51 - tensor([ 2.0000,  0.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "52 - tensor([ 2.0000,  1.0000, 32.5000,  1.0000,  0.0000, 30.0708,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "53 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "54 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "55 - tensor([  1.0000,   0.0000,  43.0000,   0.0000,   1.0000, 211.3375,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "56 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "57 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 19.9667,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "58 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "59 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "60 - tensor([ 2.0000,  0.0000, 54.0000,  1.0000,  3.0000, 23.0000,  2.0000, 21.1792,\n",
      "         3.0000,  4.0000,  0.0000]): 1\n",
      "61 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 34.0208,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "62 - tensor([ 2.0000,  0.0000, 32.5000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "63 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "64 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   0.0000, 133.6500,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "65 - tensor([  1.0000,   0.0000,  45.0000,   1.0000,   1.0000, 164.8667,   2.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "66 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "67 - tensor([ 3.0000,  1.0000, 45.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "68 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  1.0000, 57.9792,  0.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "69 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "70 - tensor([ 2.0000,  1.0000, 29.0000,  1.0000,  0.0000, 27.7208,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "71 - tensor([ 2.0000,  1.0000,  0.8300,  0.0000,  2.0000, 29.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "72 - tensor([ 1.0000,  1.0000, 65.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "73 - tensor([ 1.0000,  1.0000, 65.0000,  0.0000,  1.0000, 61.9792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "74 - tensor([  1.0000,   0.0000,  31.0000,   0.0000,   2.0000, 164.8667,   2.0000,\n",
      "         87.5090,   1.0000,   2.0000,   0.0000]): 1\n",
      "75 - tensor([ 3.0000,  0.0000, 43.0000,  1.0000,  6.0000, 46.9000,  2.0000, 13.3029,\n",
      "         3.0000,  7.0000,  0.0000]): 0\n",
      "76 - tensor([ 2.0000,  1.0000, 19.0000,  1.0000,  1.0000, 36.7500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "77 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "78 - tensor([ 1.0000,  0.0000, 26.0000,  0.0000,  0.0000, 78.8500,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "79 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "80 - tensor([ 3.0000,  1.0000, 29.0000,  2.0000,  0.0000, 23.2500,  1.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "81 - tensor([ 2.0000,  1.0000, 52.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "82 - tensor([ 2.0000,  1.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "83 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 31.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "84 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "85 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "86 - tensor([ 1.0000,  0.0000, 44.0000,  0.0000,  1.0000, 57.9792,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "87 - tensor([ 2.0000,  0.0000,  5.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "88 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "89 - tensor([ 3.0000,  1.0000,  4.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 0\n",
      "90 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "91 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 50.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "92 - tensor([ 3.0000,  0.0000, 29.0000,  0.0000,  4.0000, 21.0750,  2.0000, 13.3029,\n",
      "         3.0000,  4.0000,  0.0000]): 0\n",
      "93 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8875,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "94 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "95 - tensor([ 1.0000,  0.0000, 22.0000,  0.0000,  2.0000, 49.5000,  0.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "96 - tensor([ 1.0000,  1.0000, 34.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "97 - tensor([ 2.0000,  0.0000, 23.0000,  0.0000,  0.0000, 13.7917,  0.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "98 - tensor([ 3.0000,  1.0000, 40.0000,  1.0000,  1.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "99 - tensor([  1.0000,   1.0000,  50.0000,   1.0000,   0.0000, 106.4250,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "100 - tensor([ 1.0000,  1.0000, 45.5000,  0.0000,  0.0000, 28.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "101 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "102 - tensor([  1.0000,   1.0000,  29.0000,   0.0000,   0.0000, 221.7792,   2.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "103 - tensor([ 3.0000,  1.0000, 59.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "104 - tensor([ 1.0000,  1.0000, 31.0000,  1.0000,  0.0000, 57.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "105 - tensor([ 3.0000,  1.0000, 43.0000,  0.0000,  0.0000,  6.4500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "106 - tensor([ 1.0000,  1.0000, 23.0000,  0.0000,  1.0000, 63.3583,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "107 - tensor([ 1.0000,  1.0000, 27.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "108 - tensor([ 2.0000,  1.0000, 21.0000,  0.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "109 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "110 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 35.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "111 - tensor([ 3.0000,  1.0000,  2.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "112 - tensor([ 2.0000,  1.0000, 51.0000,  0.0000,  0.0000, 12.5250,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "113 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "114 - tensor([  1.0000,   1.0000,  36.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   2.0000,   3.0000,   0.0000]): 1\n",
      "115 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "116 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "117 - tensor([ 2.0000,  0.0000, 45.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "118 - tensor([ 3.0000,  1.0000, 24.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "119 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  8.3000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "120 - tensor([ 3.0000,  0.0000, 30.0000,  0.0000,  0.0000, 12.4750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "121 - tensor([ 3.0000,  1.0000, 17.0000,  1.0000,  0.0000,  7.0542,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "122 - tensor([ 2.0000,  0.0000,  2.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "123 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 30.6958,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "124 - tensor([ 2.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "125 - tensor([ 2.0000,  0.0000, 34.0000,  0.0000,  1.0000, 23.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "126 - tensor([ 3.0000,  1.0000, 45.0000,  0.0000,  0.0000,  6.9750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "127 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "128 - tensor([ 3.0000,  1.0000,  8.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "129 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "130 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "131 - tensor([ 1.0000,  0.0000, 49.0000,  1.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "132 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "133 - tensor([ 2.0000,  0.0000, 25.0000,  1.0000,  1.0000, 30.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "134 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "135 - tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         0.0000,  4.0000,  0.0000]): 0\n",
      "136 - tensor([ 3.0000,  0.0000, 20.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "137 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "138 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "139 - tensor([ 1.0000,  1.0000, 45.0000,  1.0000,  0.0000, 83.4750,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "140 - tensor([ 3.0000,  1.0000, 24.0000,  2.0000,  0.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "141 - tensor([ 3.0000,  0.0000, 38.0000,  1.0000,  5.0000, 31.3875,  2.0000, 13.3029,\n",
      "         3.0000,  6.0000,  0.0000]): 1\n",
      "142 - tensor([ 1.0000,  1.0000, 21.0000,  0.0000,  1.0000, 77.2875,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "143 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "144 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 0\n",
      "145 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "146 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7875,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "147 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.7417,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "148 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  2.0000, 14.5000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "149 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  2.0000, 11.1333,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "150 - tensor([ 3.0000,  0.0000, 28.0000,  1.0000,  1.0000, 14.4000,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "151 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "152 - tensor([ 2.0000,  0.0000, 36.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "153 - tensor([ 3.0000,  1.0000, 14.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         2.0000,  5.0000,  0.0000]): 0\n",
      "154 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "155 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000, 18.7875,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "156 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 51.8625,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "157 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 15.1000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "158 - tensor([ 1.0000,  0.0000, 32.0000,  0.0000,  0.0000, 76.2917,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "159 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  1.0000,  8.4042,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "160 - tensor([ 3.0000,  0.0000,  2.0000,  0.0000,  1.0000, 10.4625,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "161 - tensor([ 2.0000,  0.0000, 17.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "162 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "163 - tensor([ 3.0000,  0.0000, 37.0000,  0.0000,  0.0000,  9.5875,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "164 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "165 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 83.1583,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "166 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000, 10.5167,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "167 - tensor([ 2.0000,  0.0000, 33.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "168 - tensor([ 3.0000,  1.0000, 47.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "169 - tensor([ 1.0000,  1.0000, 24.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "170 - tensor([  1.0000,   1.0000,  58.0000,   0.0000,   2.0000, 113.2750,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "171 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "172 - tensor([ 3.0000,  1.0000, 37.0000,  2.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "173 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "174 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "175 - tensor([ 3.0000,  1.0000, 10.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "176 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "177 - tensor([ 3.0000,  0.0000,  5.0000,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "178 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "179 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "180 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "181 - tensor([ 2.0000,  1.0000, 16.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "182 - tensor([ 2.0000,  0.0000, 24.0000,  2.0000,  3.0000, 18.7500,  2.0000, 21.1792,\n",
      "         3.0000,  5.0000,  0.0000]): 1\n",
      "183 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "184 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "185 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "186 - tensor([ 2.0000,  0.0000, 25.0000,  0.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "187 - tensor([ 1.0000,  1.0000, 60.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "188 - tensor([ 2.0000,  1.0000, 33.0000,  0.0000,  0.0000, 12.2750,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "189 - tensor([ 2.0000,  1.0000, 36.5000,  0.0000,  2.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "190 - tensor([ 1.0000,  1.0000, 37.0000,  1.0000,  1.0000, 52.5542,  2.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "191 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "192 - tensor([ 3.0000,  0.0000,  5.0000,  0.0000,  0.0000, 12.4750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "193 - tensor([  1.0000,   1.0000,  35.0000,   0.0000,   0.0000, 512.3292,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 1\n",
      "194 - tensor([ 3.0000,  0.0000,  0.7500,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "195 - tensor([ 3.0000,  1.0000,  3.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 1\n",
      "196 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "197 - tensor([ 3.0000,  0.0000, 14.0000,  1.0000,  0.0000, 11.2417,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "198 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "199 - tensor([ 1.0000,  0.0000, 51.0000,  1.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "200 - tensor([ 2.0000,  0.0000, 40.0000,  1.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "201 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "202 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "203 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "204 - tensor([ 2.0000,  0.0000, 55.0000,  0.0000,  0.0000, 16.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "205 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  2.0000, 23.4500,  2.0000, 13.3029,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "206 - tensor([ 3.0000,  0.0000, 31.0000,  1.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "207 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "208 - tensor([ 3.0000,  0.0000, 15.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "209 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.4583,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "210 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "211 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.4833,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "212 - tensor([ 3.0000,  0.0000, 48.0000,  1.0000,  3.0000, 34.3750,  2.0000, 13.3029,\n",
      "         3.0000,  4.0000,  0.0000]): 0\n",
      "213 - tensor([ 3.0000,  0.0000, 21.0000,  1.0000,  0.0000,  9.8250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "214 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.2250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "215 - tensor([ 3.0000,  0.0000, 20.0000,  1.0000,  0.0000,  9.8250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "216 - tensor([ 2.0000,  0.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "217 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "218 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7375,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "219 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "220 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 25.5875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "221 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "222 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "223 - tensor([ 1.0000,  0.0000, 54.0000,  1.0000,  0.0000, 78.2667,  0.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "224 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "225 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  8.6542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "226 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "227 - tensor([ 2.0000,  0.0000, 14.0000,  1.0000,  0.0000, 30.0708,  0.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "228 - tensor([ 3.0000,  1.0000, 22.0000,  1.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "229 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "230 - tensor([  1.0000,   0.0000,  23.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   1.0000,   5.0000,   0.0000]): 1\n",
      "231 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "232 - tensor([ 2.0000,  0.0000, 22.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "233 - tensor([ 2.0000,  1.0000, 32.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "234 - tensor([ 3.0000,  0.0000,  5.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 1\n",
      "235 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "236 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "237 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "238 - tensor([ 2.0000,  0.0000, 24.0000,  1.0000,  2.0000, 65.0000,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "239 - tensor([ 3.0000,  0.0000, 15.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "240 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "241 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "242 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "243 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "244 - tensor([ 2.0000,  0.0000, 29.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "245 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "246 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  8.3625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "247 - tensor([  1.0000,   0.0000,  31.0000,   1.0000,   0.0000, 113.2750,   0.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "248 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "249 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  1.0000, 79.6500,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "250 - tensor([ 2.0000,  1.0000, 32.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "251 - tensor([ 3.0000,  0.0000, 35.0000,  1.0000,  1.0000, 20.2500,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "252 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "253 - tensor([ 1.0000,  1.0000, 28.0000,  1.0000,  0.0000, 82.1708,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "254 - tensor([ 2.0000,  1.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "255 - tensor([ 1.0000,  1.0000, 49.0000,  1.0000,  0.0000, 89.1042,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "256 - tensor([ 2.0000,  0.0000,  8.0000,  0.0000,  2.0000, 26.2500,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "257 - tensor([  1.0000,   0.0000,  24.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   1.0000,   5.0000,   0.0000]): 1\n",
      "258 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "259 - tensor([ 3.0000,  0.0000, 31.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "260 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "261 - tensor([ 2.0000,  0.0000, 40.0000,  0.0000,  0.0000, 15.7500,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "262 - tensor([ 1.0000,  1.0000, 33.0000,  0.0000,  0.0000,  5.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "263 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "264 - tensor([ 2.0000,  0.0000, 41.0000,  0.0000,  1.0000, 19.5000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "265 - tensor([  1.0000,   0.0000,  18.0000,   2.0000,   2.0000, 262.3750,   0.0000,\n",
      "         87.5090,   1.0000,   4.0000,   0.0000]): 1\n",
      "266 - tensor([ 1.0000,  1.0000, 25.0000,  1.0000,  0.0000, 91.0792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "267 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "268 - tensor([ 2.0000,  1.0000, 25.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "269 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  2.0000, 15.2458,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "270 - tensor([ 2.0000,  1.0000, 59.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "271 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.8000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "272 - tensor([ 2.0000,  0.0000, 17.0000,  0.0000,  0.0000, 12.0000,  0.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "273 - tensor([ 2.0000,  0.0000, 27.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "274 - tensor([ 3.0000,  1.0000, 16.0000,  1.0000,  1.0000, 20.2500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "275 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "276 - tensor([ 1.0000,  1.0000, 62.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "277 - tensor([ 2.0000,  0.0000, 24.0000,  2.0000,  1.0000, 27.0000,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "278 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "279 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 83.4750,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "280 - tensor([ 3.0000,  1.0000, 17.0000,  1.0000,  1.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "281 - tensor([ 1.0000,  1.0000, 71.0000,  0.0000,  0.0000, 34.6542,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "282 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "283 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "284 - tensor([ 1.0000,  0.0000, 48.0000,  1.0000,  0.0000, 39.6000,  0.0000, 87.5090,\n",
      "         4.0000,  1.0000,  0.0000]): 1\n",
      "285 - tensor([ 3.0000,  0.0000, 23.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "286 - tensor([ 1.0000,  0.0000, 54.0000,  1.0000,  0.0000, 59.4000,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "287 - tensor([ 3.0000,  0.0000,  9.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "288 - tensor([ 2.0000,  1.0000, 43.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "289 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000, 17.8000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "290 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "291 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "292 - tensor([ 3.0000,  0.0000, 63.0000,  0.0000,  0.0000,  9.5875,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "293 - tensor([ 3.0000,  1.0000, 11.0000,  0.0000,  0.0000, 18.7875,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "294 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  0.0000,  6.4958,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "295 - tensor([ 1.0000,  1.0000, 50.0000,  1.0000,  0.0000, 55.9000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "296 - tensor([ 3.0000,  1.0000, 43.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "297 - tensor([  1.0000,   0.0000,  22.0000,   0.0000,   0.0000, 151.5500,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "298 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "299 - tensor([ 3.0000,  1.0000,  7.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "300 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "301 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "302 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "303 - tensor([ 1.0000,  0.0000, 50.0000,  0.0000,  0.0000, 28.7125,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "304 - tensor([ 3.0000,  0.0000,  3.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "305 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 35.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "306 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 31.0000,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "307 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  1.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "308 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "309 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "310 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "311 - tensor([ 3.0000,  0.0000,  1.0000,  1.0000,  1.0000, 11.1333,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "312 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "313 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 93.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "314 - tensor([  1.0000,   1.0000,  27.0000,   0.0000,   2.0000, 211.5000,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "315 - tensor([ 1.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.5500,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "316 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "317 - tensor([ 2.0000,  0.0000, 34.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "318 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "319 - tensor([ 1.0000,  1.0000, 52.0000,  1.0000,  1.0000, 79.6500,  2.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "320 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "321 - tensor([ 3.0000,  1.0000, 47.0000,  0.0000,  0.0000,  9.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "322 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 26.2875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "323 - tensor([  1.0000,   0.0000,  42.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "324 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "325 - tensor([ 3.0000,  0.0000, 26.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "326 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  3.0000, 19.2583,  0.0000, 13.3029,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "327 - tensor([  1.0000,   1.0000,  19.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   2.0000,   5.0000,   0.0000]): 0\n",
      "328 - tensor([ 2.0000,  1.0000, 31.0000,  1.0000,  1.0000, 37.0042,  0.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "329 - tensor([ 2.0000,  1.0000, 54.0000,  0.0000,  0.0000, 14.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "330 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "331 - tensor([ 2.0000,  1.0000, 50.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "332 - tensor([ 3.0000,  1.0000, 40.5000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "333 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "334 - tensor([ 3.0000,  1.0000,  7.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "335 - tensor([ 3.0000,  1.0000, 24.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "336 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "337 - tensor([ 2.0000,  1.0000, 30.0000,  1.0000,  0.0000, 24.0000,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "338 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "339 - tensor([ 1.0000,  0.0000, 53.0000,  2.0000,  0.0000, 51.4792,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "340 - tensor([ 1.0000,  0.0000, 17.0000,  1.0000,  0.0000, 57.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "341 - tensor([  1.0000,   0.0000,  58.0000,   0.0000,   0.0000, 146.5208,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "342 - tensor([ 1.0000,  1.0000, 25.0000,  1.0000,  0.0000, 55.4417,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "343 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "344 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "345 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "346 - tensor([ 2.0000,  0.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "347 - tensor([ 3.0000,  0.0000,  4.0000,  0.0000,  2.0000, 22.0250,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "348 - tensor([ 2.0000,  0.0000, 28.0000,  0.0000,  0.0000, 12.6500,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "349 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  1.0000, 22.3583,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "350 - tensor([ 3.0000,  0.0000, 29.0000,  0.0000,  2.0000, 15.2458,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "351 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "352 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "353 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.7125,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "354 - tensor([ 3.0000,  1.0000, 12.0000,  1.0000,  0.0000, 11.2417,  0.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "355 - tensor([ 1.0000,  0.0000, 36.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "356 - tensor([ 3.0000,  0.0000,  8.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "357 - tensor([ 2.0000,  0.0000,  7.0000,  0.0000,  2.0000, 26.2500,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "358 - tensor([ 1.0000,  0.0000, 38.0000,  1.0000,  0.0000, 71.2833,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "359 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "360 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "361 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "362 - tensor([  1.0000,   0.0000,  29.0000,   0.0000,   0.0000, 211.3375,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "363 - tensor([ 1.0000,  0.0000, 22.0000,  1.0000,  0.0000, 66.6000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "364 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "365 - tensor([ 1.0000,  1.0000, 60.0000,  1.0000,  1.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "366 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "367 - tensor([ 1.0000,  0.0000, 21.0000,  0.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "368 - tensor([ 2.0000,  0.0000, 50.0000,  0.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "369 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "370 - tensor([ 3.0000,  0.0000,  4.0000,  0.0000,  1.0000, 13.4167,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "371 - tensor([ 2.0000,  0.0000,  4.0000,  1.0000,  1.0000, 23.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "372 - tensor([ 3.0000,  1.0000,  6.0000,  0.0000,  1.0000, 12.4750,  2.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "373 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "374 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "375 - tensor([ 1.0000,  1.0000, 54.0000,  0.0000,  0.0000, 51.8625,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "376 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  0.0000,  8.8500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "377 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.1417,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "378 - tensor([ 3.0000,  1.0000, 16.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         2.0000,  5.0000,  0.0000]): 0\n",
      "379 - tensor([ 3.0000,  1.0000, 30.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "380 - tensor([ 3.0000,  0.0000, 39.0000,  0.0000,  5.0000, 29.1250,  1.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "381 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 15.0500,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "382 - tensor([ 2.0000,  0.0000, 28.0000,  1.0000,  0.0000, 24.0000,  0.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "383 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "384 - tensor([ 1.0000,  1.0000, 32.0000,  0.0000,  0.0000, 30.5000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "385 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "386 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "387 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "388 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  1.0000, 12.4750,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "389 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "390 - tensor([ 3.0000,  1.0000, 40.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "391 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "392 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "393 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "394 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "395 - tensor([ 3.0000,  0.0000, 22.0000,  2.0000,  0.0000, 23.2500,  1.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "396 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 56.9292,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "397 - tensor([ 2.0000,  1.0000, 54.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         4.0000,  1.0000,  0.0000]): 0\n",
      "398 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "399 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "400 - tensor([ 1.0000,  0.0000, 49.0000,  0.0000,  0.0000, 25.9292,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "401 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 90.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "402 - tensor([ 3.0000,  1.0000, 41.0000,  2.0000,  0.0000, 14.1083,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "403 - tensor([ 3.0000,  0.0000, 30.0000,  1.0000,  1.0000, 24.1500,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "404 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  1.0000, 39.4000,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "405 - tensor([ 3.0000,  1.0000, 49.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "406 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "407 - tensor([  1.0000,   0.0000,  58.0000,   0.0000,   1.0000, 153.4625,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "408 - tensor([ 3.0000,  0.0000, 16.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "409 - tensor([ 1.0000,  1.0000, 49.0000,  0.0000,  0.0000, 39.6000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "410 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "411 - tensor([ 1.0000,  1.0000, 58.0000,  0.0000,  0.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "412 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  9.3500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "413 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "414 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "415 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "416 - tensor([ 2.0000,  1.0000, 46.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "417 - tensor([ 3.0000,  0.0000,  9.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         1.0000,  5.0000,  0.0000]): 0\n",
      "418 - tensor([ 2.0000,  1.0000, 47.0000,  0.0000,  0.0000, 15.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "419 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "420 - tensor([ 3.0000,  0.0000,  4.0000,  1.0000,  1.0000, 16.7000,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "421 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.6958,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "422 - tensor([ 2.0000,  1.0000, 66.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "423 - tensor([ 2.0000,  1.0000, 31.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "424 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "425 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "426 - tensor([ 3.0000,  0.0000, 10.0000,  0.0000,  2.0000, 24.1500,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "427 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "428 - tensor([ 2.0000,  1.0000,  0.8300,  1.0000,  1.0000, 18.7500,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "429 - tensor([ 3.0000,  1.0000, 40.5000,  0.0000,  2.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "430 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "431 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "432 - tensor([ 3.0000,  0.0000, 14.5000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "433 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "434 - tensor([ 1.0000,  1.0000, 40.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "435 - tensor([ 2.0000,  0.0000, 50.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "436 - tensor([ 3.0000,  0.0000, 45.0000,  1.0000,  4.0000, 27.9000,  2.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "437 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "438 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "439 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "440 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "441 - tensor([  1.0000,   0.0000,  23.0000,   1.0000,   0.0000, 113.2750,   0.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "442 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "443 - tensor([ 1.0000,  1.0000, 38.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "444 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "445 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "446 - tensor([  1.0000,   1.0000,  22.0000,   0.0000,   0.0000, 135.6333,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "447 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  6.8583,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "448 - tensor([ 2.0000,  0.0000, 29.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "449 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "450 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "451 - tensor([ 1.0000,  1.0000, 70.0000,  1.0000,  1.0000, 71.0000,  2.0000, 87.5090,\n",
      "         4.0000,  2.0000,  0.0000]): 0\n",
      "452 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "453 - tensor([ 2.0000,  0.0000, 31.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "454 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "455 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  4.0125,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "456 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "457 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "458 - tensor([ 3.0000,  1.0000, 38.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "459 - tensor([  1.0000,   0.0000,  22.0000,   0.0000,   0.0000, 110.8833,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "460 - tensor([  1.0000,   1.0000,  17.0000,   0.0000,   2.0000, 110.8833,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 1\n",
      "461 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 89.1042,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "462 - tensor([ 1.0000,  1.0000, 38.0000,  1.0000,  0.0000, 90.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "463 - tensor([ 2.0000,  0.0000, 27.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "464 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "465 - tensor([  1.0000,   0.0000,  14.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   1.0000,   3.0000,   0.0000]): 1\n",
      "466 - tensor([  1.0000,   1.0000,  24.0000,   0.0000,   1.0000, 247.5208,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "467 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "468 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.5208,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "469 - tensor([ 3.0000,  1.0000, 39.0000,  1.0000,  5.0000, 31.2750,  2.0000, 13.3029,\n",
      "         2.0000,  6.0000,  0.0000]): 0\n",
      "470 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  8.1375,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "471 - tensor([ 1.0000,  0.0000, 18.0000,  0.0000,  2.0000, 79.6500,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "472 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  9.8375,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "473 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "474 - tensor([ 3.0000,  1.0000,  9.0000,  0.0000,  2.0000, 20.5250,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "475 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "476 - tensor([ 2.0000,  0.0000, 28.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "477 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "478 - tensor([ 2.0000,  1.0000, 54.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "479 - tensor([ 3.0000,  0.0000, 19.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "480 - tensor([ 2.0000,  0.0000, 40.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "481 - tensor([ 3.0000,  1.0000,  9.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "482 - tensor([ 3.0000,  0.0000, 18.0000,  1.0000,  0.0000, 17.8000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "483 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "484 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  9.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "485 - tensor([ 3.0000,  0.0000, 39.0000,  1.0000,  5.0000, 31.2750,  2.0000, 13.3029,\n",
      "         3.0000,  6.0000,  0.0000]): 0\n",
      "486 - tensor([  1.0000,   1.0000,  11.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   0.0000,   3.0000,   0.0000]): 1\n",
      "487 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "488 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "489 - tensor([ 3.0000,  1.0000, 14.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         2.0000,  7.0000,  0.0000]): 0\n",
      "490 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.1125,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "491 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "492 - tensor([ 2.0000,  0.0000, 18.0000,  0.0000,  2.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "493 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "494 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  6.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "495 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 13.8625,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "496 - tensor([ 3.0000,  1.0000, 38.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "497 - tensor([ 1.0000,  1.0000, 27.0000,  0.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "498 - tensor([ 2.0000,  0.0000, 30.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "499 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "500 - tensor([ 3.0000,  1.0000, 28.5000,  0.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "501 - tensor([ 3.0000,  1.0000,  2.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "502 - tensor([ 1.0000,  1.0000, 27.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "503 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "504 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "505 - tensor([  1.0000,   1.0000,  36.0000,   0.0000,   1.0000, 512.3292,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 1\n",
      "506 - tensor([ 3.0000,  0.0000,  2.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "507 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 35.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "508 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "509 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   0.0000, 146.5208,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "510 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  6.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "511 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "512 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "513 - tensor([ 1.0000,  0.0000, 52.0000,  1.0000,  0.0000, 78.2667,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "514 - tensor([ 3.0000,  0.0000, 26.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "515 - tensor([ 3.0000,  1.0000, 23.5000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "516 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "517 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "518 - tensor([ 3.0000,  1.0000, 65.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "519 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "520 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "521 - tensor([ 1.0000,  0.0000, 33.0000,  1.0000,  0.0000, 90.0000,  1.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "522 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "523 - tensor([ 2.0000,  0.0000, 24.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "524 - tensor([ 3.0000,  0.0000, 21.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "525 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "526 - tensor([ 1.0000,  1.0000, 61.0000,  0.0000,  0.0000, 32.3208,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "527 - tensor([ 3.0000,  1.0000,  9.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 0\n",
      "528 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "529 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "530 - tensor([ 1.0000,  1.0000, 31.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "531 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  2.0000, 20.5750,  2.0000, 13.3029,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "532 - tensor([  1.0000,   0.0000,  30.0000,   0.0000,   0.0000, 106.4250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "533 - tensor([ 3.0000,  0.0000, 25.0000,  1.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "534 - tensor([ 2.0000,  1.0000, 57.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "535 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "536 - tensor([ 1.0000,  1.0000, 52.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "537 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "538 - tensor([ 2.0000,  0.0000, 45.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "539 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "540 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "541 - tensor([ 3.0000,  1.0000, 16.0000,  2.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "542 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 38.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "543 - tensor([ 2.0000,  0.0000, 21.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "544 - tensor([ 3.0000,  1.0000,  3.0000,  1.0000,  1.0000, 15.9000,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "545 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "546 - tensor([ 1.0000,  1.0000, 51.0000,  0.0000,  1.0000, 61.3792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "547 - tensor([ 2.0000,  1.0000, 37.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "548 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "549 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "550 - tensor([ 2.0000,  1.0000, 31.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "551 - tensor([ 3.0000,  0.0000, 16.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "552 - tensor([ 2.0000,  0.0000, 38.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "553 - tensor([ 2.0000,  0.0000, 13.0000,  0.0000,  1.0000, 19.5000,  2.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "554 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "555 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  6.9500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "556 - tensor([ 2.0000,  0.0000, 42.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "557 - tensor([ 1.0000,  1.0000, 51.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "558 - tensor([ 3.0000,  0.0000, 32.0000,  1.0000,  1.0000, 15.5000,  1.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "559 - tensor([ 3.0000,  1.0000,  4.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         0.0000, 10.0000,  0.0000]): 0\n",
      "560 - tensor([ 2.0000,  1.0000, 21.0000,  2.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "561 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 25.9250,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "562 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "563 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 47.1000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "564 - tensor([  1.0000,   0.0000,  15.0000,   0.0000,   1.0000, 211.3375,   2.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "565 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "566 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "567 - tensor([  1.0000,   0.0000,  18.0000,   1.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "568 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 11.1333,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "569 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "570 - tensor([ 3.0000,  1.0000, 61.0000,  0.0000,  0.0000,  6.2375,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "571 - tensor([ 3.0000,  0.0000, 47.0000,  1.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "572 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "573 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "574 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.3125,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "575 - tensor([ 3.0000,  0.0000,  1.0000,  0.0000,  2.0000, 15.7417,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "576 - tensor([ 2.0000,  0.0000, 48.0000,  1.0000,  2.0000, 65.0000,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "577 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "578 - tensor([ 2.0000,  1.0000, 26.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "579 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "580 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "581 - tensor([ 3.0000,  0.0000,  6.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "582 - tensor([ 3.0000,  0.0000, 41.0000,  0.0000,  5.0000, 39.6875,  2.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "583 - tensor([ 1.0000,  0.0000, 33.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "584 - tensor([ 3.0000,  0.0000,  9.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "585 - tensor([ 3.0000,  1.0000, 28.0000,  2.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "586 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7375,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "587 - tensor([ 3.0000,  0.0000, 40.0000,  1.0000,  0.0000,  9.4750,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "588 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "589 - tensor([ 3.0000,  1.0000, 51.0000,  0.0000,  0.0000,  7.0542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "590 - tensor([ 2.0000,  0.0000, 22.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "591 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "592 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "593 - tensor([ 1.0000,  1.0000, 46.0000,  1.0000,  0.0000, 61.1750,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "594 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.1708,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "595 - tensor([  1.0000,   0.0000,  35.0000,   0.0000,   0.0000, 135.6333,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "596 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "597 - tensor([ 3.0000,  1.0000, 40.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "598 - tensor([ 3.0000,  1.0000, 50.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "599 - tensor([ 3.0000,  0.0000, 21.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "600 - tensor([  1.0000,   0.0000,  40.0000,   0.0000,   0.0000, 153.4625,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "601 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "602 - tensor([  1.0000,   1.0000,  50.0000,   2.0000,   0.0000, 133.6500,   2.0000,\n",
      "         87.5090,   4.0000,   2.0000,   0.0000]): 1\n",
      "603 - tensor([ 1.0000,  0.0000, 58.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "604 - tensor([ 3.0000,  1.0000, 15.0000,  1.0000,  1.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "605 - tensor([ 2.0000,  1.0000, 44.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "606 - tensor([ 2.0000,  1.0000, 29.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "607 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "608 - tensor([ 2.0000,  1.0000, 35.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "609 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "610 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "611 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "612 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  1.0000, 83.1583,  0.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "613 - tensor([ 3.0000,  1.0000, 20.0000,  1.0000,  1.0000, 15.7417,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "614 - tensor([ 3.0000,  1.0000, 40.0000,  1.0000,  4.0000, 27.9000,  2.0000, 13.3029,\n",
      "         2.0000,  5.0000,  0.0000]): 0\n",
      "615 - tensor([ 3.0000,  0.0000,  9.0000,  2.0000,  2.0000, 34.3750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "616 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "617 - tensor([  1.0000,   0.0000,  36.0000,   0.0000,   0.0000, 135.6333,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "618 - tensor([ 3.0000,  1.0000, 36.0000,  1.0000,  0.0000, 15.5500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "619 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  2.0000, 16.7000,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "620 - tensor([ 3.0000,  0.0000, 30.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "621 - tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "622 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "623 - tensor([ 2.0000,  1.0000, 42.0000,  1.0000,  0.0000, 27.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "624 - tensor([ 3.0000,  0.0000, 15.0000,  0.0000,  0.0000,  8.0292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "625 - tensor([ 2.0000,  1.0000,  1.0000,  2.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         0.0000,  3.0000,  0.0000]): 1\n",
      "626 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "627 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "628 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  9.2167,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "629 - tensor([ 2.0000,  0.0000,  6.0000,  0.0000,  1.0000, 33.0000,  2.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "630 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "631 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "632 - tensor([ 1.0000,  1.0000, 30.0000,  0.0000,  0.0000, 27.7500,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "633 - tensor([ 1.0000,  0.0000, 48.0000,  0.0000,  0.0000, 25.9292,  2.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "634 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "635 - tensor([ 3.0000,  1.0000, 28.0000,  1.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "636 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "637 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "638 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "639 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 35.5000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "640 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "641 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7250,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "642 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  1.0000, 33.0000,  2.0000, 21.1792,\n",
      "         4.0000,  1.0000,  0.0000]): 0\n",
      "643 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  9.2250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "644 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "645 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "646 - tensor([ 3.0000,  1.0000,  1.0000,  1.0000,  2.0000, 20.5750,  2.0000, 13.3029,\n",
      "         0.0000,  3.0000,  0.0000]): 1\n",
      "647 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "648 - tensor([ 2.0000,  1.0000, 24.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "649 - tensor([ 1.0000,  0.0000, 44.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "650 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.1583,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "651 - tensor([ 2.0000,  1.0000,  2.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "652 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "653 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  6.9750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "654 - tensor([ 2.0000,  1.0000, 31.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "655 - tensor([ 3.0000,  1.0000,  9.0000,  1.0000,  1.0000, 15.9000,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "656 - tensor([ 1.0000,  1.0000, 37.0000,  0.0000,  1.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "657 - tensor([ 3.0000,  0.0000, 17.0000,  0.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "658 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "659 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "660 - tensor([ 1.0000,  1.0000, 46.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "661 - tensor([ 2.0000,  1.0000,  3.0000,  1.0000,  1.0000, 18.7500,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "662 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  6.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "663 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "664 - tensor([ 3.0000,  0.0000,  0.7500,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "665 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.8458,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "666 - tensor([  1.0000,   1.0000,   0.9200,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   0.0000,   3.0000,   0.0000]): 1\n",
      "667 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  1.0000,  9.3500,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "668 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "669 - tensor([  1.0000,   1.0000,  64.0000,   1.0000,   4.0000, 263.0000,   2.0000,\n",
      "         87.5090,   2.0000,   5.0000,   0.0000]): 0\n",
      "670 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "671 - tensor([ 2.0000,  0.0000, 19.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "672 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  1.0000, 20.2125,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "673 - tensor([ 3.0000,  1.0000,  1.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "674 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "675 - tensor([ 3.0000,  0.0000, 45.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "676 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "677 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "678 - tensor([ 3.0000,  0.0000, 26.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "679 - tensor([ 1.0000,  1.0000, 44.0000,  2.0000,  0.0000, 90.0000,  1.0000, 87.5090,\n",
      "         4.0000,  2.0000,  0.0000]): 0\n",
      "680 - tensor([ 3.0000,  0.0000, 14.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "681 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "682 - tensor([ 2.0000,  0.0000,  4.0000,  2.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "683 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "684 - tensor([ 1.0000,  0.0000, 62.0000,  0.0000,  0.0000, 80.0000,  3.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "685 - tensor([ 3.0000,  0.0000, 23.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "686 - tensor([ 3.0000,  0.0000, 11.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "687 - tensor([ 2.0000,  0.0000, 44.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "688 - tensor([ 3.0000,  1.0000, 11.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "689 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7292,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "690 - tensor([ 1.0000,  1.0000,  4.0000,  0.0000,  2.0000, 81.8583,  2.0000, 87.5090,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "691 - tensor([ 3.0000,  0.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "692 - tensor([ 1.0000,  1.0000, 42.0000,  1.0000,  0.0000, 52.5542,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "693 - tensor([ 2.0000,  1.0000,  8.0000,  1.0000,  1.0000, 36.7500,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "694 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "695 - tensor([ 1.0000,  1.0000, 31.0000,  0.0000,  0.0000, 50.4958,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "696 - tensor([ 2.0000,  1.0000, 23.0000,  2.0000,  1.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "697 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "698 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "699 - tensor([ 2.0000,  1.0000, 70.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "700 - tensor([ 1.0000,  0.0000, 47.0000,  1.0000,  1.0000, 52.5542,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "701 - tensor([ 3.0000,  0.0000, 21.0000,  2.0000,  2.0000, 34.3750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "702 - tensor([ 1.0000,  1.0000, 48.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "703 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "704 - tensor([ 2.0000,  0.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "705 - tensor([ 2.0000,  0.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "706 - tensor([ 3.0000,  1.0000, 30.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "707 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "708 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "709 - tensor([ 3.0000,  1.0000, 20.5000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "710 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "711 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "712 - tensor([ 3.0000,  0.0000, 31.0000,  1.0000,  1.0000, 20.5250,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "################################################## 2\n",
      "[TRAIN]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([16, 11]): torch.Size([16])\n",
      "12 - torch.Size([16, 11]): torch.Size([16])\n",
      "13 - torch.Size([16, 11]): torch.Size([16])\n",
      "14 - torch.Size([16, 11]): torch.Size([16])\n",
      "15 - torch.Size([16, 11]): torch.Size([16])\n",
      "16 - torch.Size([16, 11]): torch.Size([16])\n",
      "17 - torch.Size([16, 11]): torch.Size([16])\n",
      "18 - torch.Size([16, 11]): torch.Size([16])\n",
      "19 - torch.Size([16, 11]): torch.Size([16])\n",
      "20 - torch.Size([16, 11]): torch.Size([16])\n",
      "21 - torch.Size([16, 11]): torch.Size([16])\n",
      "22 - torch.Size([16, 11]): torch.Size([16])\n",
      "23 - torch.Size([16, 11]): torch.Size([16])\n",
      "24 - torch.Size([16, 11]): torch.Size([16])\n",
      "25 - torch.Size([16, 11]): torch.Size([16])\n",
      "26 - torch.Size([16, 11]): torch.Size([16])\n",
      "27 - torch.Size([16, 11]): torch.Size([16])\n",
      "28 - torch.Size([16, 11]): torch.Size([16])\n",
      "29 - torch.Size([16, 11]): torch.Size([16])\n",
      "30 - torch.Size([16, 11]): torch.Size([16])\n",
      "31 - torch.Size([16, 11]): torch.Size([16])\n",
      "32 - torch.Size([16, 11]): torch.Size([16])\n",
      "33 - torch.Size([16, 11]): torch.Size([16])\n",
      "34 - torch.Size([16, 11]): torch.Size([16])\n",
      "35 - torch.Size([16, 11]): torch.Size([16])\n",
      "36 - torch.Size([16, 11]): torch.Size([16])\n",
      "37 - torch.Size([16, 11]): torch.Size([16])\n",
      "38 - torch.Size([16, 11]): torch.Size([16])\n",
      "39 - torch.Size([16, 11]): torch.Size([16])\n",
      "40 - torch.Size([16, 11]): torch.Size([16])\n",
      "41 - torch.Size([16, 11]): torch.Size([16])\n",
      "42 - torch.Size([16, 11]): torch.Size([16])\n",
      "43 - torch.Size([16, 11]): torch.Size([16])\n",
      "44 - torch.Size([9, 11]): torch.Size([9])\n",
      "[VALIDATION]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([2, 11]): torch.Size([2])\n",
      "################################################## 3\n",
      "[TEST]\n",
      "torch.Size([418, 11])\n",
      "892 1\n",
      "893 1\n",
      "894 1\n",
      "895 1\n",
      "896 1\n",
      "897 1\n",
      "898 1\n",
      "899 1\n",
      "900 1\n",
      "901 1\n",
      "902 1\n",
      "903 1\n",
      "904 1\n",
      "905 1\n",
      "906 1\n",
      "907 1\n",
      "908 1\n",
      "909 1\n",
      "910 1\n",
      "911 1\n",
      "912 1\n",
      "913 1\n",
      "914 1\n",
      "915 1\n",
      "916 1\n",
      "917 1\n",
      "918 1\n",
      "919 1\n",
      "920 1\n",
      "921 1\n",
      "922 1\n",
      "923 1\n",
      "924 1\n",
      "925 1\n",
      "926 1\n",
      "927 1\n",
      "928 1\n",
      "929 1\n",
      "930 1\n",
      "931 1\n",
      "932 1\n",
      "933 1\n",
      "934 1\n",
      "935 1\n",
      "936 1\n",
      "937 1\n",
      "938 1\n",
      "939 1\n",
      "940 1\n",
      "941 1\n",
      "942 1\n",
      "943 1\n",
      "944 1\n",
      "945 1\n",
      "946 1\n",
      "947 1\n",
      "948 1\n",
      "949 1\n",
      "950 1\n",
      "951 1\n",
      "952 1\n",
      "953 1\n",
      "954 1\n",
      "955 1\n",
      "956 1\n",
      "957 1\n",
      "958 1\n",
      "959 1\n",
      "960 1\n",
      "961 1\n",
      "962 1\n",
      "963 1\n",
      "964 1\n",
      "965 1\n",
      "966 1\n",
      "967 1\n",
      "968 1\n",
      "969 1\n",
      "970 1\n",
      "971 1\n",
      "972 1\n",
      "973 1\n",
      "974 1\n",
      "975 1\n",
      "976 1\n",
      "977 1\n",
      "978 1\n",
      "979 1\n",
      "980 1\n",
      "981 1\n",
      "982 1\n",
      "983 1\n",
      "984 1\n",
      "985 1\n",
      "986 1\n",
      "987 1\n",
      "988 1\n",
      "989 1\n",
      "990 1\n",
      "991 1\n",
      "992 1\n",
      "993 1\n",
      "994 1\n",
      "995 1\n",
      "996 1\n",
      "997 1\n",
      "998 1\n",
      "999 1\n",
      "1000 1\n",
      "1001 1\n",
      "1002 1\n",
      "1003 1\n",
      "1004 1\n",
      "1005 1\n",
      "1006 1\n",
      "1007 1\n",
      "1008 1\n",
      "1009 1\n",
      "1010 1\n",
      "1011 1\n",
      "1012 1\n",
      "1013 1\n",
      "1014 1\n",
      "1015 1\n",
      "1016 1\n",
      "1017 1\n",
      "1018 1\n",
      "1019 1\n",
      "1020 1\n",
      "1021 1\n",
      "1022 1\n",
      "1023 1\n",
      "1024 1\n",
      "1025 1\n",
      "1026 1\n",
      "1027 1\n",
      "1028 1\n",
      "1029 1\n",
      "1030 1\n",
      "1031 1\n",
      "1032 1\n",
      "1033 1\n",
      "1034 1\n",
      "1035 1\n",
      "1036 1\n",
      "1037 1\n",
      "1038 1\n",
      "1039 1\n",
      "1040 1\n",
      "1041 1\n",
      "1042 1\n",
      "1043 1\n",
      "1044 1\n",
      "1045 1\n",
      "1046 1\n",
      "1047 1\n",
      "1048 1\n",
      "1049 1\n",
      "1050 1\n",
      "1051 1\n",
      "1052 1\n",
      "1053 1\n",
      "1054 1\n",
      "1055 1\n",
      "1056 1\n",
      "1057 1\n",
      "1058 1\n",
      "1059 1\n",
      "1060 1\n",
      "1061 1\n",
      "1062 1\n",
      "1063 1\n",
      "1064 1\n",
      "1065 1\n",
      "1066 1\n",
      "1067 1\n",
      "1068 1\n",
      "1069 1\n",
      "1070 1\n",
      "1071 1\n",
      "1072 1\n",
      "1073 1\n",
      "1074 1\n",
      "1075 1\n",
      "1076 1\n",
      "1077 1\n",
      "1078 1\n",
      "1079 1\n",
      "1080 1\n",
      "1081 1\n",
      "1082 1\n",
      "1083 1\n",
      "1084 1\n",
      "1085 1\n",
      "1086 1\n",
      "1087 1\n",
      "1088 1\n",
      "1089 1\n",
      "1090 1\n",
      "1091 1\n",
      "1092 1\n",
      "1093 1\n",
      "1094 1\n",
      "1095 1\n",
      "1096 1\n",
      "1097 1\n",
      "1098 1\n",
      "1099 1\n",
      "1100 1\n",
      "1101 1\n",
      "1102 1\n",
      "1103 1\n",
      "1104 1\n",
      "1105 1\n",
      "1106 1\n",
      "1107 1\n",
      "1108 1\n",
      "1109 1\n",
      "1110 1\n",
      "1111 1\n",
      "1112 1\n",
      "1113 1\n",
      "1114 1\n",
      "1115 1\n",
      "1116 1\n",
      "1117 1\n",
      "1118 1\n",
      "1119 1\n",
      "1120 1\n",
      "1121 1\n",
      "1122 1\n",
      "1123 1\n",
      "1124 1\n",
      "1125 1\n",
      "1126 1\n",
      "1127 1\n",
      "1128 1\n",
      "1129 1\n",
      "1130 1\n",
      "1131 1\n",
      "1132 1\n",
      "1133 1\n",
      "1134 1\n",
      "1135 1\n",
      "1136 1\n",
      "1137 1\n",
      "1138 1\n",
      "1139 1\n",
      "1140 1\n",
      "1141 1\n",
      "1142 1\n",
      "1143 1\n",
      "1144 1\n",
      "1145 1\n",
      "1146 1\n",
      "1147 1\n",
      "1148 1\n",
      "1149 1\n",
      "1150 1\n",
      "1151 1\n",
      "1152 1\n",
      "1153 1\n",
      "1154 1\n",
      "1155 1\n",
      "1156 1\n",
      "1157 1\n",
      "1158 1\n",
      "1159 1\n",
      "1160 1\n",
      "1161 1\n",
      "1162 1\n",
      "1163 1\n",
      "1164 1\n",
      "1165 1\n",
      "1166 1\n",
      "1167 1\n",
      "1168 1\n",
      "1169 1\n",
      "1170 1\n",
      "1171 1\n",
      "1172 1\n",
      "1173 1\n",
      "1174 1\n",
      "1175 1\n",
      "1176 1\n",
      "1177 1\n",
      "1178 1\n",
      "1179 1\n",
      "1180 1\n",
      "1181 1\n",
      "1182 1\n",
      "1183 1\n",
      "1184 1\n",
      "1185 1\n",
      "1186 1\n",
      "1187 1\n",
      "1188 1\n",
      "1189 1\n",
      "1190 1\n",
      "1191 1\n",
      "1192 1\n",
      "1193 1\n",
      "1194 1\n",
      "1195 1\n",
      "1196 1\n",
      "1197 1\n",
      "1198 1\n",
      "1199 1\n",
      "1200 1\n",
      "1201 1\n",
      "1202 1\n",
      "1203 1\n",
      "1204 1\n",
      "1205 1\n",
      "1206 1\n",
      "1207 1\n",
      "1208 1\n",
      "1209 1\n",
      "1210 1\n",
      "1211 1\n",
      "1212 1\n",
      "1213 1\n",
      "1214 1\n",
      "1215 1\n",
      "1216 1\n",
      "1217 1\n",
      "1218 1\n",
      "1219 1\n",
      "1220 1\n",
      "1221 1\n",
      "1222 1\n",
      "1223 1\n",
      "1224 1\n",
      "1225 1\n",
      "1226 1\n",
      "1227 1\n",
      "1228 1\n",
      "1229 1\n",
      "1230 1\n",
      "1231 1\n",
      "1232 1\n",
      "1233 1\n",
      "1234 1\n",
      "1235 1\n",
      "1236 1\n",
      "1237 1\n",
      "1238 1\n",
      "1239 1\n",
      "1240 1\n",
      "1241 1\n",
      "1242 1\n",
      "1243 1\n",
      "1244 1\n",
      "1245 1\n",
      "1246 1\n",
      "1247 1\n",
      "1248 1\n",
      "1249 1\n",
      "1250 1\n",
      "1251 1\n",
      "1252 1\n",
      "1253 1\n",
      "1254 1\n",
      "1255 1\n",
      "1256 1\n",
      "1257 1\n",
      "1258 1\n",
      "1259 1\n",
      "1260 1\n",
      "1261 1\n",
      "1262 1\n",
      "1263 1\n",
      "1264 1\n",
      "1265 1\n",
      "1266 1\n",
      "1267 1\n",
      "1268 1\n",
      "1269 1\n",
      "1270 1\n",
      "1271 1\n",
      "1272 1\n",
      "1273 1\n",
      "1274 1\n",
      "1275 1\n",
      "1276 1\n",
      "1277 1\n",
      "1278 1\n",
      "1279 1\n",
      "1280 1\n",
      "1281 1\n",
      "1282 1\n",
      "1283 1\n",
      "1284 1\n",
      "1285 1\n",
      "1286 1\n",
      "1287 1\n",
      "1288 1\n",
      "1289 1\n",
      "1290 1\n",
      "1291 1\n",
      "1292 1\n",
      "1293 1\n",
      "1294 1\n",
      "1295 1\n",
      "1296 1\n",
      "1297 1\n",
      "1298 1\n",
      "1299 1\n",
      "1300 1\n",
      "1301 1\n",
      "1302 1\n",
      "1303 1\n",
      "1304 1\n",
      "1305 1\n",
      "1306 1\n",
      "1307 1\n",
      "1308 1\n",
      "1309 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 훈련, 검증, 테스트 데이터셋 생성\n",
    "    train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "    print(\"train_dataset: {0}, validation_dataset.shape: {1}, test_dataset: {2}\".format(\n",
    "        len(train_dataset), len(validation_dataset), len(test_dataset)\n",
    "    ))\n",
    "    print(\"#\" * 50, 1)\n",
    "\n",
    "    for idx, sample in enumerate(train_dataset):\n",
    "        print(\"{0} - {1}: {2}\".format(idx, sample['input'], sample['target']))\n",
    "\n",
    "    print(\"#\" * 50, 2)\n",
    "\n",
    "    # 훈련 데이터셋을 DataLoader에 넣음, 배치 사이즈는 16으로, 데이터를 섞어서 사용\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "    # 검증 데이터셋을 배치 사이즈 16으로, 데이터를 섞어서 사용\n",
    "    validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=16, shuffle=True)\n",
    "    # 테스트 데이터셋은 한 번에 출력함(배치 사이즈가 테스트 데이터셋 크기)\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "    # 훈련 데이터를 배치 크기 단위로 출력\n",
    "    print(\"[TRAIN]\")\n",
    "    for idx, batch in enumerate(train_data_loader):\n",
    "        print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "    # 검증 데이터를 배치 크기 단위로 출력\n",
    "    print(\"[VALIDATION]\")\n",
    "    for idx, batch in enumerate(validation_data_loader):\n",
    "        print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "    print(\"#\" * 50, 3)\n",
    "\n",
    "    # 테스트 데이터의 예측 수행\n",
    "    test(test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003a86f",
   "metadata": {},
   "source": [
    "### 요구사항 2. 타이타닉 데이터로 코드 수정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d692e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정한 코드는 한 덩어리로 올렸습니다.\n",
    "# 실행은 PyCharm에서 해서, Jupiter에선 실행하지 않았습니다.\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import wandb\n",
    "import argparse\n",
    "\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "class TitanicTestDataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "\n",
    "# 기존 titanic_dataset을 활용\n",
    "def get_preprocessed_dataset():\n",
    "    CURRENT_FILE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "    train_data_path = os.path.join(CURRENT_FILE_PATH, \"train.csv\")\n",
    "    test_data_path = os.path.join(CURRENT_FILE_PATH, \"test.csv\")\n",
    "\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "    all_df = get_preprocessed_dataset_1(all_df)\n",
    "    all_df = get_preprocessed_dataset_2(all_df)\n",
    "    all_df = get_preprocessed_dataset_3(all_df)\n",
    "    all_df = get_preprocessed_dataset_4(all_df)\n",
    "    all_df = get_preprocessed_dataset_5(all_df)\n",
    "    all_df = get_preprocessed_dataset_6(all_df)\n",
    "\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    train_y = train_df[\"Survived\"]\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "\n",
    "    train_dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "    train_dataset, validation_dataset = random_split(train_dataset, [0.8, 0.2])\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset\n",
    "\n",
    "# 모델 수정을 많이 거쳤음\n",
    "# 배치 정규화를 사용했고, 결과에서 가장 괜찮게 나왔다고 생각한 값은 PReLU여서 활성화 함수는 PReLU를 사용했음\n",
    "# Dropout을 사용하여 생길 수 있는 오버피팅의 문제를 해결했음. 0.3~0.5중에서 0.4가 가장 Valid_less가 작았음\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(32, n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def get_preprocessed_dataset():\n",
    "    CURRENT_FILE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터의 파일 경로 지정\n",
    "    train_data_path = os.path.join(CURRENT_FILE_PATH, \"train.csv\")\n",
    "    test_data_path = os.path.join(CURRENT_FILE_PATH, \"test.csv\")\n",
    "\n",
    "    # DataFrame으로 각 CSV 파일을 읽어옴\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    # 정렬 안 하고 DataFrame을 합침\n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "    # 1 ~ 6까지 전처리 함수 호출\n",
    "    all_df = get_preprocessed_dataset_1(all_df)\n",
    "    all_df = get_preprocessed_dataset_2(all_df)\n",
    "    all_df = get_preprocessed_dataset_3(all_df)\n",
    "    all_df = get_preprocessed_dataset_4(all_df)\n",
    "    all_df = get_preprocessed_dataset_5(all_df)\n",
    "    all_df = get_preprocessed_dataset_6(all_df)\n",
    "\n",
    "    # Survived가 null이 아니라면 훈련 데이터로 사용하고, 기존 인덱스를 초기화하기 위해 reset_index 사용\n",
    "    # 훈련 데이터에서는 Survived이 null이 아닌 행만을 선택하여 사용\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    # 학습해야 할 데이터인 Survived는 따로 추출해놓음\n",
    "    train_y = train_df[\"Survived\"]\n",
    "\n",
    "    # 테스트 데이터에서는 Survived가 null인 행만을 선택하여 사용\n",
    "    # 삭제하는 이유는 테스트에서는 Survived를 제거 -> 정답이 없기에\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "\n",
    "    # TitanicDataset을 이용해 학습용 데이터셋을 생성\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "    # print(dataset)\n",
    "    # 훈련 데이터셋은 80%, 검증 데이터셋은 20%로 분할\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "    # 테스트 데이터는 TitanicTestDataset으로 변환\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "    # print(test_dataset)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset\n",
    "\n",
    "\n",
    "def get_preprocessed_dataset_1(all_df):\n",
    "    # Pclass별 Fare 평균값을 사용하여 Fare 결측치 메우기\n",
    "    Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "    Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]\n",
    "    all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "\n",
    "    return all_df\n",
    "\n",
    "\n",
    "def get_preprocessed_dataset_2(all_df):\n",
    "    # name을 세 개의 컬럼으로 분리하여 다시 all_df에 합침\n",
    "    name_df = all_df[\"Name\"].str.split(\"[,.]\", n=2, expand=True)\n",
    "    name_df.columns = [\"family_name\", \"honorific\", \"name\"]\n",
    "    name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "    name_df[\"honorific\"] = name_df[\"honorific\"].str.strip()\n",
    "    name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "    all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "\n",
    "def get_preprocessed_dataset_3(all_df):\n",
    "    # honorific별 Age 평균값을 사용하여 Age 결측치 메우기\n",
    "    honorific_age_mean = all_df[[\"honorific\", \"Age\"]].groupby(\"honorific\").median().round().reset_index()\n",
    "    honorific_age_mean.columns = [\"honorific\", \"honorific_age_mean\", ]\n",
    "    all_df = pd.merge(all_df, honorific_age_mean, on=\"honorific\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"honorific_age_mean\"]\n",
    "    all_df = all_df.drop([\"honorific_age_mean\"], axis=1)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "\n",
    "def get_preprocessed_dataset_4(all_df):\n",
    "    # 가족수(family_num) 컬럼 새롭게 추가\n",
    "    all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "\n",
    "    # 혼자탑승(alone) 컬럼 새롭게 추가\n",
    "    all_df.loc[all_df[\"family_num\"] == 0, \"alone\"] = 1\n",
    "    all_df[\"alone\"].fillna(0, inplace=True)\n",
    "\n",
    "    # 학습에 불필요한 컬럼 제거\n",
    "    all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "\n",
    "def get_preprocessed_dataset_5(all_df):\n",
    "    # honorific 값 개수 줄이기\n",
    "    all_df.loc[\n",
    "        ~(\n",
    "                (all_df[\"honorific\"] == \"Mr\") |\n",
    "                (all_df[\"honorific\"] == \"Miss\") |\n",
    "                (all_df[\"honorific\"] == \"Mrs\") |\n",
    "                (all_df[\"honorific\"] == \"Master\")\n",
    "        ),\n",
    "        \"honorific\"\n",
    "    ] = \"other\"\n",
    "    all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "\n",
    "def get_preprocessed_dataset_6(all_df):\n",
    "    # 카테고리 변수를 LabelEncoder를 사용하여 수치값으로 변경하기\n",
    "    category_features = all_df.columns[all_df.dtypes == \"object\"]\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for category_feature in category_features:\n",
    "        le = LabelEncoder()\n",
    "        if all_df[category_feature].dtypes == \"object\":\n",
    "            le = le.fit(all_df[category_feature])\n",
    "            all_df[category_feature] = le.transform(all_df[category_feature])\n",
    "\n",
    "    return all_df\n",
    "\n",
    "# 예측값 저장 메소드\n",
    "def predict_and_save(model, test_loader, filename=\"submission.csv\"):\n",
    "    # 모델 평가 모드로 설정, 레이어가 훈련 모드가 아닌 고정된 모드로 지정\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    # 역전파 수행 X -> 예측속도 증가\n",
    "    with torch.no_grad():\n",
    "        # 미니 배치 기준으로 입력을 받고, 예측 결과를 얻음\n",
    "        for inputs in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            # 행 기준 각 샘플의 최대값 찾음\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.tolist())\n",
    "\n",
    "    # submission.csv 생성\n",
    "    # 승객 번호는 892번부터 시작, 예측 번호를 할당\n",
    "    submission = pd.DataFrame({\"PassengerId\": range(892, 892 + len(predictions)), \"Survived\": predictions})\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"Saved predictions to {filename}\")\n",
    "\n",
    "# 모델 최적화 함수\n",
    "def get_model_and_optimizer(n_input):\n",
    "    # 이진 분류(0 또는 1)를 실행\n",
    "    model = MyModel(n_input=n_input, n_output=2)\n",
    "    # Wandb를 통하여 학습률을 받아서 사용\n",
    "    optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "    return model, optimizer\n",
    "\n",
    "def training_loop(model, optimizer, train_loader, val_loader, test_loader):\n",
    "    # 분류문제에서 자주 사용하는 CrossEntorypyLoss 함수를 사용\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    n_epochs = wandb.config.epochs\n",
    "\n",
    "    # 초기값 설정\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss, total = 0, 0\n",
    "\n",
    "        # 훈련 단계\n",
    "        for inputs, targets in train_loader:\n",
    "            # 입력에 대한 예측 수행\n",
    "            outputs = model(inputs)\n",
    "            # 입력에 대한 loss 계산\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            # 이전 gradient 초기화\n",
    "            optimizer.zero_grad()\n",
    "            # gradient를 역전파를 수행하여 정의\n",
    "            loss.backward()\n",
    "            # 파라미터를 업데이트 함\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total += 1\n",
    "\n",
    "        val_loss, val_total = 0, 0\n",
    "        # 모델 평가모드로 변경\n",
    "        model.eval()\n",
    "        # 평가 중에는 gradient 변화 X\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                # 검증 데이터 예측\n",
    "                outputs = model(inputs)\n",
    "                # loss 계산\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                val_total += 1\n",
    "\n",
    "        # wandb에 로그를 기록\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": total_loss / total,\n",
    "            \"val_loss\": val_loss / val_total\n",
    "        })\n",
    "\n",
    "        # Validation loss가 개선될 때마다 테스트 예측 수행\n",
    "        # 여기서 위에서 서술한 predict_and_save 메소드를 수행\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            print(f\"Epoch {epoch}, New Best Val Loss: {val_loss / val_total}.\")\n",
    "            predict_and_save(model, test_loader)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Train Loss: {total_loss / total}, Val Loss: {val_loss / val_total}\")\n",
    "\n",
    "def main(args):\n",
    "    wandb.init(\n",
    "        project=\"titanic_model\",\n",
    "        # lr을 1e-3 -> 1e-4로 변경(값 변동이 너무 커서)\n",
    "        config={\n",
    "            \"epochs\": args.epochs,\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"learning_rate\": 1e-4,\n",
    "        }\n",
    "    )\n",
    "    # test_dataset을 추가\n",
    "    train_dataset, val_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "    # shuffle을 이용하여 데이터를 섞어서 사용\n",
    "    train_loader = DataLoader(train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=wandb.config.batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=wandb.config.batch_size)\n",
    "\n",
    "    # 입력 차원을 받아서 model, optimizer를 생성\n",
    "    model, optimizer = get_model_and_optimizer(n_input=train_dataset[0][0].shape[0])\n",
    "    # 모델, optimizer, train_loader, val_loader, test_loader를 넣고 훈련 시작\n",
    "    training_loop(model, optimizer, train_loader, val_loader, test_loader)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1000)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11834c7",
   "metadata": {},
   "source": [
    "### 요구사항 2. Wandb 링크 걸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c570fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU - https://wandb.ai/duehee-korea-university-of-technology-and-education/titanic_model/runs/j8rij9ow\n",
    "# PReLU - https://wandb.ai/duehee-korea-university-of-technology-and-education/titanic_model/runs/sik3hxfc\n",
    "# ReakyReLU - https://wandb.ai/duehee-korea-university-of-technology-and-education/titanic_model/runs/yeejbq0y\n",
    "# ELU - https://wandb.ai/duehee-korea-university-of-technology-and-education/titanic_model/runs/lxr9zm7h\n",
    "    \n",
    "# 제시한 활성함수를 모두 사용해보았다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fdbb4",
   "metadata": {},
   "source": [
    "### 요구사항 2. 더 나은 결과를 제공하는 활성화 함수 생각하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc69fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용해 본 결과는 아래와 같다.\n",
    "# ReLU : Train_loss와 Valid_loss가 평균이다. 각 loss의 차이가 크지 않아 이상적이다.\n",
    "# PReLU : 압도적으로 Valid_loss가 작게 나왔다. Valid_loss가 작을수록 훈련 데이터에 크게 영향을 받지 않는다고 하여 위에선 PReLU를 사용했다.\n",
    "# ReakyReLU : Train_loss가 가장 작게 나온 값이었다. 4개 중엔 Loss의 차이가 가장 컸다.\n",
    "# ELU : 각 loss의 차이가 크진 않았지만, 그렇다고 특출나지 않은 결과를 보여서 사용하진 않았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b64381",
   "metadata": {},
   "source": [
    "### 요구사항 3. 가장 좋은 활성화 함수로 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10517c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요구사항 2에서 PReLU로 구현헀다.\n",
    "# 어느 Epoch가 가장 좋은가? -> 테스트 과정에서는 Valid_loss가 최소인 값을 best 값이라고 생각하고 값을 적용하고 저장했다.\n",
    "# 그 내용은 추가적으로 training_loop 및 predict_and_save 메소드를 이용하여 구현했다.\n",
    "# submission.scv도 생성하여 Kaggle에 제출했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe5c4b3",
   "metadata": {},
   "source": [
    "### 요구사항 4. Kaggle에 제출 및 등수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "733183a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename=\"Kaggle.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed017d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc76b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
