### 기술적 고찰
이번 과제를 진행하며 코드를 이래저래 수정하는 과정을 많이 거쳤는데, 초반엔 loss들이 출력되는 것만으로도 신기했다.
하지만 진행하면서 loss가 생각보다 많이 감소하지 않는 것을 보면서 어떻게 할 지 고민을 해보며, 활성화 함수도 바꾸어보고,
learning_rate도 수정해보고, dropout도 추가해보면서 여러가지 테스트도 해보았다. 개인적으로는 learning_rate의 수정이
loss의 값을 가장 크게 바꾸어주어 0.37..까지의 loss의 감소를 기대할 수 있었다. 이를 고민하면서 valid_loss가 작은 것이
가장 과연 좋은 것일까? 고려해보았는데, 평균적으로는 train_loss와 valid_loss의 차이가 가장 적은게 일반적으로 사용하기 좋고,
이처럼 예측이 필요한 경우엔 valid_loss가 낮은 것이 좋다고 하여 이를 사용해보았는데, 2250등이라는 좋은 등수를 거둘 수 있었다.

### 숙제 후기
위의 기술적 고찰을 서술하면서 느낀 점이 많은데, 생각보다 0.01~0.02의 차이도 몇 천등씩 차이나는 걸 보고 놀랐다.
어떻게 하면 더 줄일 수 있을까? 하고 고민해보며 코드를 많이 수정해보았는데. 이 과정도 꽤 재밌었다.
여러가지로 수정하면서 valid_loss가 2까지도 올라가는 것을 보기도 하고, 원하는 대로 안정도 되지 않는 것을 보며
답답했지만, 어느새 어느 값에 수렴하는 loss값을 통해 제출하는 과정이 신기했던 것 같다. 0.8 이상의 값은 어떻게 하면
얻을 수 있을지 좀 생각해보면 좋을 것 같다.
